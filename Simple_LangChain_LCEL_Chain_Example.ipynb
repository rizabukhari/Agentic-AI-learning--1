{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizabukhari/Agentic-AI-projects/blob/main/Simple_LangChain_LCEL_Chain_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UD0sNgttG1M"
      },
      "source": [
        "# Simple LangChain LCEL Chain Example\n",
        "\n",
        "This notebook shows how to create a simple LLM Chain using LangChain's new LangChain Expression Language (LCEL) syntax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19XTN_hMiBZY"
      },
      "source": [
        "## Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzXw3x6be5JH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain #==0.3.11\n",
        "!pip install langchain-openai #==0.2.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5pyPRU4iVOy"
      },
      "source": [
        "## Setup Open AI API credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6ChC0K9e5JJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm5l_l_7ioaV"
      },
      "source": [
        "## Connect to the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F6iaMmdinxH"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "from langchain_openai import ChatOpenAI\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-5-mini\") #, temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drMdp1XVs9Hv"
      },
      "source": [
        "## Create LCEL LLM Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKsCborniZxE"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# create a prompt template to accept user queries\n",
        "prompt_txt = \"{query}\"\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt_txt)\n",
        "\n",
        "# the chain has been formatted for better readability\n",
        "# you could also write this as llmchain = prompt_template | chatgpt\n",
        "llmchain = (prompt_template | chatgpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1JzZt0xtAUf"
      },
      "source": [
        "## Run the LLM Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z-pC6PdjuFc",
        "outputId": "63fc00b6-407d-499c-e0c0-9d9b1d086f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Short answer:\n",
            "\n",
            "- AI agent: any software/system that perceives inputs and takes actions to achieve tasks or objectives (examples: chatbots, web crawlers, RL agents, rule-based bots). Can be simple and tightly scripted or reactive.\n",
            "\n",
            "- Agentic AI: describes systems that exhibit agency — autonomous, goal-directed behavior including planning, decision-making, tool use, and initiative across extended tasks (examples: LLM-based agents that plan, call tools, and pursue multi-step goals without step-by-step user prompting).\n",
            "\n",
            "Key difference: “AI agent” names an entity; “agentic AI” emphasizes the level of autonomy and self-directed capability. Not all AI agents are agentic; agentic AI implies higher autonomy, complexity, and potential need for stronger oversight/safety controls.\n"
          ]
        }
      ],
      "source": [
        "response = llmchain.invoke({'query' : 'Explain the difference between AI Agents and Agentic AI in short'})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "id": "aR4X6n9ifQCD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "a3b79d18-cad5-4dc7-effc-f91f98bcbe59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Short answer:\n\n- AI agent: any software/system that perceives inputs and takes actions to achieve tasks or objectives (examples: chatbots, web crawlers, RL agents, rule-based bots). Can be simple and tightly scripted or reactive.\n\n- Agentic AI: describes systems that exhibit agency — autonomous, goal-directed behavior including planning, decision-making, tool use, and initiative across extended tasks (examples: LLM-based agents that plan, call tools, and pursue multi-step goals without step-by-step user prompting).\n\nKey difference: “AI agent” names an entity; “agentic AI” emphasizes the level of autonomy and self-directed capability. Not all AI agents are agentic; agentic AI implies higher autonomy, complexity, and potential need for stronger oversight/safety controls."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbxxsqm8PsAl",
        "outputId": "b2613bf8-8ca1-41bb-bd8f-2a620c7e5283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Short answer:\\n\\n- AI agent: any software/system that perceives inputs and takes actions to achieve tasks or objectives (examples: chatbots, web crawlers, RL agents, rule-based bots). Can be simple and tightly scripted or reactive.\\n\\n- Agentic AI: describes systems that exhibit agency — autonomous, goal-directed behavior including planning, decision-making, tool use, and initiative across extended tasks (examples: LLM-based agents that plan, call tools, and pursue multi-step goals without step-by-step user prompting).\\n\\nKey difference: “AI agent” names an entity; “agentic AI” emphasizes the level of autonomy and self-directed capability. Not all AI agents are agentic; agentic AI implies higher autonomy, complexity, and potential need for stronger oversight/safety controls.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 421, 'prompt_tokens': 18, 'total_tokens': 439, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cwu3w12OOfJrJWWOXAwX2P7XkmIeJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bae39-8232-7970-bc88-93d4bdbc3a8c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 18, 'output_tokens': 421, 'total_tokens': 439, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llmchain.invoke({'query' : 'Tabulate the differences between Traditional AI and Generative AI'})\n",
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x1vG21oyPt8z",
        "outputId": "bb3bf932-c9cb-42d0-b5d1-37bc2a86e15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Below is a concise tabular comparison between Traditional AI and Generative AI.\n\n| Aspect | Traditional AI | Generative AI |\n|---|---:|---|\n|Definition|Systems that use rules, symbolic logic, or discriminative/decision-making models to solve specific tasks (classification, prediction, optimization).|Models that learn to generate new data (text, images, audio, code) that resemble training data distributions.|\n|Primary objective|Make accurate decisions, classifications, predictions, or follow rules. |Create plausible, novel content or data samples.|\n|Typical approaches|Rule-based systems, expert systems, classical ML (logistic regression, SVM, decision trees), reinforcement learning for control.|Generative models: autoregressive models (transformers/LLMs), GANs, VAEs, diffusion models.|\n|Training signal|Often supervised (labeled) or reinforcement signals focused on task-specific loss (accuracy, reward).|Often self-supervised or unsupervised (predict next token/pixel), or adversarial/likelihood-based objectives.|\n|Output type|Discrete decisions, labels, scores, or actions (e.g., classify email spam, control robot).|High-dimensional content: natural language, images, audio, code, synthetic data.|\n|Examples|Spam classifier, fraud detection, rule-based medical expert system, traditional computer vision pipelines.|ChatGPT, DALL·E, Stable Diffusion, StyleGAN, Codex.|\n|Evaluation metrics|Accuracy, precision/recall, F1, ROC-AUC, task-specific metrics. |Perplexity, BLEU/ROUGE, FID/IS for images, human evaluation for quality/faithfulness.|\n|Creativity & novelty|Limited — follows learned decision boundaries or rules; novelty is not the goal. |Designed to produce novel, diverse, and creative outputs.|\n|Determinism & repeatability|Often deterministic or predictable given same inputs and model weights. |Often probabilistic; outputs can vary across runs unless sampling is fixed.|\n|Interpretability|Typically more interpretable (rules, feature weights, decision paths) especially for simpler models. |Often less interpretable (large neural networks, latent spaces), explaining why a particular output was generated is harder.|\n|Data & compute needs|Can work with moderate-sized labeled datasets and modest compute for many classical models. |Usually requires very large datasets and significant compute for training; fine-tuning is also compute-heavy.|\n|Failure modes|Misclassification, brittle rule coverage, overfitting to training labels. |Hallucinations (confident but incorrect fabrications), biased or toxic outputs, mode collapse (GANs).|\n|Controllability|High — behavior constrained by rules or objective; easier to enforce constraints. |Harder — needs prompt engineering, conditioning, or additional control mechanisms (RLHF, classifiers).|\n|Typical use cases|Automation, decision support, detection/monitoring, optimization, control systems.|Content creation, data augmentation, conversational agents, creative design, code generation.|\n|Human-in-the-loop|Often used with human oversight for decision thresholds or rule adjustments. |Often requires human oversight for validation, filtering, and fine-grained control of outputs.|\n|Regulatory / ethical concerns|Bias and fairness issues around decisions; easier to audit in many cases. |Amplified concerns: misinformation, IP/privacy issues, deepfakes, harder to audit/explain.|\n|Deployment characteristics|Lower-latency inference for many applications; resource requirements can be modest. |Inference can be resource-intensive (especially large LLMs, high-res image models); latency varies by model and deployment setup.|\n|When to choose|When you need reliable, explainable decisions or have limited data/compute and a well-defined task. |When you need to generate novel content, synthesize data, or perform open-ended language/image tasks. |\n\nIf you want, I can:\n- Produce a shorter cheat-sheet version,\n- Add specific examples for your domain (e.g., healthcare, finance, marketing),\n- Or convert this into a CSV/Excel-friendly format for download."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIJQxk8lQJAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AIpAQ8VQMWO",
        "outputId": "15b7160e-4259-491f-b951-17af117d602c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Aspect | Traditional AI | Generative AI |\n",
            "|---|---:|---|\n",
            "| Definition | Systems that use algorithms to perform tasks, make decisions, or classify/predict based on rules or learned patterns. | Models that learn probability distributions over data to generate new, plausible content (text, images, audio, code, etc.). |\n",
            "| Primary goal | Accurate prediction, classification, optimization, decision-making. | Produce novel, coherent, and contextually appropriate content. |\n",
            "| Typical outputs | Labels, scores, decisions, recommendations, control signals. | Free-form content: text, images, audio, video, code, structured data. |\n",
            "| Core techniques | Classical ML (logistic regression, SVM, decision trees), rule-based systems, expert systems, reinforcement learning for control. | Deep generative models (transformers, VAEs, GANs, diffusion models, autoregressive models). |\n",
            "| Training objective | Minimize prediction/error (e.g., cross-entropy, MSE) for a defined target variable. | Model likelihood, reconstruction loss, adversarial loss, or diffusion denoising objectives to approximate data distribution. |\n",
            "| Data requirements | Labeled datasets for supervised tasks; structured features often suffice. | Large-scale, diverse unlabeled (or weakly labeled) datasets; benefits from massive-scale pretraining. |\n",
            "| Output determinism | Often deterministic or constrained; repeatable given same inputs and model state. | Typically probabilistic and may produce different outputs for same prompt; sampling introduces variability. |\n",
            "| Creativity/novelty | Limited — tends to reproduce learned patterns or rules. | High — designed to synthesize novel combinations and generate unseen content. |\n",
            "| Interpretability | Often more interpretable (especially simpler models); explainability methods established. | Generally less interpretable (large, opaque neural networks); explainability is an active research area. |\n",
            "| Evaluation metrics | Task-specific metrics (accuracy, precision/recall, F1, RMSE, AUC). | Both task metrics and human-centered evaluations (perplexity, BLEU/ROUGE, FID, human preference, factuality checks). |\n",
            "| Common applications | Fraud detection, predictive maintenance, classification, recommendation, control systems. | Text generation, image synthesis, code generation, creative content, conversational agents, data augmentation. |\n",
            "| Failure modes | Misclassification, overfitting, brittle rules, distribution shift. | Hallucination (fabricated facts), biased or toxic outputs, incoherence, overfitting to spurious patterns. |\n",
            "| Safety & risks | Bias and fairness concerns, but often easier to constrain outputs. | Amplified risks: hallucinations, misuse for disinformation, IP issues, harder to constrain. |\n",
            "| Control & steering | Rule constraints, explicit objective functions, conservative outputs. | Prompting, fine-tuning, RLHF, filters/safety layers, but control is probabilistic and imperfect. |\n",
            "| Resource needs | Can be lightweight depending on model; classical models often inexpensive to train/deploy. | Typically compute- and data-intensive to train; inference cost can also be high (large transformer models). |\n",
            "| Licensing & IP issues | Easier to trace training data and provenance; less generative plagiarism risk. | Complex IP and attribution concerns due to training on large web-scale corpora and content synthesis. |\n",
            "| Human oversight | Often used as decision support with clear thresholds for human-in-the-loop. | Strong need for human review, especially for high-stakes or factual content. |\n",
            "| Typical development cycle | Model design → feature engineering → training → evaluation → deployment. | Pretraining on massive data → fine-tuning/prompting → safety alignment → deployment and monitoring. |\n",
            "| Example systems | Decision trees, SVMs, rule engines, classical recommendation algorithms. | GPT, DALL·E/Stable Diffusion, Music LM, Codex, diffusion-based image models. |\n",
            "\n",
            "If you want this in CSV, fewer/more comparison rows, or focused on a particular domain (healthcare, finance, etc.), tell me and I’ll adapt it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dl33AtljQUzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}